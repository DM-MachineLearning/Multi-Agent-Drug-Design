import torch
import pandas as pd
import numpy as np
import re
import os
import sys
from tqdm import tqdm
from torch.nn.utils.rnn import pad_sequence
from transformers import PreTrainedTokenizerFast

# --- CONFIGURATION ---
# The CSV generated by your agent (e.g., run1.csv)
RESULTS_CSV = "outputs/exploration_updateMeanVar_50update.csv" 
# Your new SMILES-based model
MODEL_PATH = "smiles_admet_model.pt"
VOCAB_PATH = "./vocab.json"
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Same Filters as your Agent
FILTERS = {
    "BBBP": {"target": "high", "threshold": 0.3}, 
    "hERG_inhibition":    {"target": "high",  "threshold": 0.3},
    "CYP3A4_inhibition":  {"target": "high",  "threshold": 0.4},
}

# Regex for SMILES splitting (Must match training)
SMI_REGEX_PATTERN = r"(\[[^\]]+]|Br?|Cl?|N|O|S|P|F|I|b|c|n|o|s|p|\(|\)|\.|=|#|-|\+|\\\\|\/|:|~|@|\?|>|\*|\$|\%[0-9]{2}|[0-9])"
regex = re.compile(SMI_REGEX_PATTERN)

# --- RE-IMPORT MODEL CLASS (Must match the trainer) ---
# Paste the SMILESMultiTaskClassifier class here or import it
import torch.nn as nn
from torch.nn.utils.rnn import pack_padded_sequence

class SMILESMultiTaskClassifier(nn.Module):
    def __init__(self, vocab_size, embed_dim=128, hidden_dim=256, num_tasks=11):
        super().__init__()
        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)
        self.gru = nn.GRU(embed_dim, hidden_dim, num_layers=2, batch_first=True, bidirectional=True)
        self.shared_body = nn.Sequential(nn.Linear(hidden_dim * 2, 512), nn.BatchNorm1d(512), nn.SiLU())
        self.heads = nn.ModuleList([nn.Sequential(nn.Linear(512, 128), nn.SiLU(), nn.Linear(128, 1)) for _ in range(num_tasks)])

    def forward(self, x, lengths):
        x = self.embedding(x)
        packed_x = pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)
        _, h_n = self.gru(packed_x)
        features = torch.cat((h_n[-2], h_n[-1]), dim=1)
        shared = self.shared_body(features)
        return torch.cat([head(shared) for head in self.heads], dim=1)

def run_external_validation():
    # 1. Load Tokenizer & Model
    print("âš™ï¸ Loading Validator...")
    tokenizer = PreTrainedTokenizerFast(tokenizer_file=VOCAB_PATH)
    ckpt = torch.load(MODEL_PATH, map_location=DEVICE)
    task_names = ckpt['tasks']
    
    model = SMILESMultiTaskClassifier(len(tokenizer), num_tasks=len(task_names)).to(DEVICE)
    model.load_state_dict(ckpt['state'])
    model.eval()

    # 2. Load Generated Molecules
    df = pd.read_csv(RESULTS_CSV)
    print(f"ðŸ“– Loaded {len(df)} molecules from Agent results.")

    all_probs = []
    
    # 3. Predict in Batches
    batch_size = 128
    with torch.no_grad():
        for i in tqdm(range(0, len(df), batch_size), desc="Validating"):
            batch_smi = df['smiles'].iloc[i : i+batch_size].astype(str).tolist()
            
            tokenized = []
            lengths = []
            for smi in batch_smi:
                tokens = regex.findall(smi)
                encoded = tokenizer.encode(" ".join(tokens), add_special_tokens=True)
                tokenized.append(torch.tensor(encoded))
                lengths.append(len(encoded))
            
            x = pad_sequence(tokenized, batch_first=True, padding_value=0).to(DEVICE)
            lens = torch.tensor(lengths)
            
            logits = model(x, lens)
            probs = torch.sigmoid(logits).cpu().numpy()
            all_probs.append(probs)

    # 4. Analyze Results
    probs_array = np.vstack(all_probs)
    res_df = pd.DataFrame(probs_array, columns=task_names)
    
    # Calculate Success
    mask_herg = res_df['hERG_inhibition'] >= FILTERS['hERG_inhibition']['threshold']
    mask_cyp = res_df['CYP3A4_inhibition'] >= FILTERS['CYP3A4_inhibition']['threshold']
    mask_goal = mask_herg & mask_cyp
    
    print("\n" + "="*50)
    print(f"{'EXTERNAL VALIDATION REPORT':^50}")
    print("="*50)
    print(f"hERG Pass Rate:    {mask_herg.mean()*100:.2f}%")
    print(f"CYP3A4 Pass Rate:  {mask_cyp.mean()*100:.2f}%")
    print(f"COMBINED GOAL:     {mask_goal.mean()*100:.2f}%")
    print("="*50)
    
    # Save detailed results
    output_path = RESULTS_CSV.replace(".csv", "_validated.csv")
    res_df['smiles'] = df['smiles']
    res_df.to_csv(output_path, index=False)
    print(f"âœ… Detailed scores saved to: {output_path}")

if __name__ == "__main__":
    run_external_validation()