import os
import torch
import tempfile
import random
from pathlib import Path
from typing import List, Set

from rdkit import Chem
from rdkit.Chem import AllChem, DataStructs

# Import your existing agents
from Generators.GPT import LLM
from Generators.VAE import VAE
from madm.generators.property_agent import PropertyAgent
from madm.classifier.classifier_model import DecisionMakingAgent

# ==========================================
# 1. Dual-Memory System
# ==========================================
class MemorySystem:
    def __init__(self, max_size=1000):
        self.active_memory = set()
        self.inactive_memory = set() # "Hall of Shame"
        self.max_size = max_size

    def add_active(self, smiles_list: List[str]):
        for sm in smiles_list:
            self.active_memory.add(sm)
            # If it was previously thought inactive, remove it (correction)
            if sm in self.inactive_memory:
                self.inactive_memory.remove(sm)
        self._prune(self.active_memory)

    def add_inactive(self, smiles_list: List[str]):
        for sm in smiles_list:
            # Only add if it's not already known as active
            if sm not in self.active_memory:
                self.inactive_memory.add(sm)
        self._prune(self.inactive_memory)

    def _prune(self, memory_set: set):
        while len(memory_set) > self.max_size:
            memory_set.pop()

    def get_inactive_fingerprints(self) -> List:
        """Returns fingerprints of bad molecules to avoid."""
        fps = []
        for sm in list(self.inactive_memory)[-200:]: # Look at recent 200 failures
            mol = Chem.MolFromSmiles(sm)
            if mol:
                fps.append(AllChem.GetMorganFingerprintAsBitVect(mol, 2, 2048))
        return fps

    def sample_active(self, sample_size=32) -> List[str]:
        if not self.active_memory: return []
        if len(self.active_memory) < sample_size:
            return list(self.active_memory)
        return random.sample(list(self.active_memory), sample_size)

# ==========================================
# 3. Main Pipeline
# ==========================================
class MultiAgentPipeline:
    def __init__(self, n_gpts=2, m_vaes=2):
        print(f"--- Initializing Fleet: {n_gpts} GPTs, {m_vaes} VAEs ---")
        
        # 1. Unified Fleet List
        self.agents = []
        
        # Initialize N GPTs
        for i in range(n_gpts):
            print(f"Loading GPT Agent {i+1}...")
            agent = LLM(model_path=None)
            agent.load_model(use_lora=True)
            self.agents.append({"name": f"GPT_{i+1}", "model": agent, "type": "GPT"})

        # Initialize M VAEs
        for i in range(m_vaes):
            print(f"Loading VAE Agent {i+1}...")
            agent = VAE(model_path=None)
            agent.load_model()
            self.agents.append({"name": f"VAE_{i+1}", "model": agent, "type": "VAE"})

        self.validator = PropertyAgent()
        self.decision_agent = DecisionMakingAgent(threshold=0.4)
        self.memory = MemorySystem(max_size=1000)
        self.output_dir = Path("outputs")
        self.output_dir.mkdir(exist_ok=True)

    def _get_fp(self, smiles):
        mol = Chem.MolFromSmiles(smiles)
        return AllChem.GetMorganFingerprintAsBitVect(mol, 2, 2048) if mol else None

    def generate_smart_batch(self, generator, batch_size, avoid_fps: List):
        """
        Same logic as before, but 'avoid_fps' now includes:
        1. Known Inactive Molecules (History)
        2. Molecules generated by OTHER agents in this specific round (Peer Pressure)
        """
        accepted_mols = []
        attempts = 0
        max_attempts = batch_size * 5 

        while len(accepted_mols) < batch_size and attempts < max_attempts:
            needed = batch_size - len(accepted_mols)
            # Higher temp for later attempts to force exploration
            temp = 0.8 + (0.05 * (attempts // 10)) 
            candidates = [generator.generate_molecule(temperature=temp) for _ in range(needed + 2)]
            
            for sm in candidates:
                if len(accepted_mols) >= batch_size: break
                
                fp = self._get_fp(sm)
                if fp is None: continue 

                # UNIFIED CONSTRAINT CHECK
                # Checks against both Inactive Memory AND Peers simultaneously
                if avoid_fps:
                    sims = DataStructs.BulkTanimotoSimilarity(fp, avoid_fps)
                    if sims and max(sims) > 0.75: # Too similar to *something* we want to avoid
                        continue 

                accepted_mols.append(sm)
            attempts += 1
        
        # Fill if failed
        while len(accepted_mols) < batch_size:
            accepted_mols.append(generator.generate_molecule())
            
        return accepted_mols

    def run_optimization_loop(self, rounds=5, batch_size=20):
        """
        Batch size is per-agent. Total molecules = (N+M) * batch_size
        """
        for r in range(rounds):
            print(f"\n=== Round {r+1}/{rounds} ===")
            
            # --- PHASE 1: SEQUENTIAL GENERATION ---
            
            # 1. Load Global Taboos (Inactive History)
            # These are molecules NO ONE should generate
            global_avoid_fps = []
            if r > 0:
                global_avoid_fps = self.memory.get_inactive_fingerprints()
            
            # 2. Rolling Generation
            # This list accumulates fingerprints from Agent 1, then Agent 2...
            # The next agent must avoid everything in this list.
            current_round_fps = [] 
            all_raw_molecules = []

            for agent_dict in self.agents:
                name = agent_dict["name"]
                model = agent_dict["model"]
                
                # Combine Global Taboos + Peers' Taboos
                full_avoid_list = global_avoid_fps + current_round_fps
                
                print(f">> {name} Generating (Avoiding {len(full_avoid_list)} fingerprints)...")
                
                # Generate
                batch = self.generate_smart_batch(model, batch_size, avoid_fps=full_avoid_list)
                all_raw_molecules.extend(batch)
                
                # Update constraints for the NEXT agent
                # (Next agent cannot copy what I just made)
                new_fps = [self._get_fp(sm) for sm in batch]
                current_round_fps.extend([fp for fp in new_fps if fp is not None])

            # --- PHASE 2: VALIDATION & CLASSIFICATION ---
            print(f">> Validating {len(all_raw_molecules)} total molecules...")
            
            active_batch = []
            inactive_batch = []
            
            results = self.validator.evaluate_batch(all_raw_molecules)
            
            for item in results:
                status = self.decision_agent.classify(item)
                if status == "Active":
                    active_batch.append(item['smiles'])
                else:
                    inactive_batch.append(item['smiles'])

            print(f"   > Result: {len(active_batch)} Active | {len(inactive_batch)} Inactive")

            # --- PHASE 3: MEMORY UPDATE ---
            self.memory.add_active(active_batch)
            self.memory.add_inactive(inactive_batch)

            # --- PHASE 4: FEEDBACK (TRAINING THE FLEET) ---
            if r == 0:
                print(">> Round 1 Complete. Skipping training.")
                continue

            if len(self.memory.active_memory) > 5:
                print(f">> Training Fleet ({len(self.agents)} Agents) on Active Experience...")
                
                # Prepare Data ONCE
                training_roots = self.memory.sample_active(sample_size=10)
                augmented_data = []
                for sm in training_roots:
                    augmented_data.extend(self._randomize_smiles(sm, 20))
                
                with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.smi') as tmp:
                    for sm in augmented_data:
                        tmp.write(sm + "\n")
                    tmp_path = tmp.name
                
                try:
                    # Update EVERY agent
                    # They all learn from the collective success
                    for agent_dict in self.agents:
                        print(f"   > Fine-tuning {agent_dict['name']}...")
                        
                        # Adjust hyperparameters based on type if needed
                        if agent_dict["type"] == "GPT":
                            agent_dict["model"].fine_tune(tmp_path, epochs=1, batch_size=4, lr=2e-5)
                        else:
                            agent_dict["model"].fine_tune(tmp_path, epochs=1, batch_size=8, lr=1e-4)
                            
                finally:
                    os.remove(tmp_path)
            else:
                print(">> Not enough active molecules yet.")
    
    def _randomize_smiles(self, smiles, n):
        # (Same helper as before)
        mol = Chem.MolFromSmiles(smiles)
        if not mol: return []
        variants = {Chem.MolToSmiles(mol, canonical=True)}
        for _ in range(n*2):
            if len(variants) >= n: break
            variants.add(Chem.MolToSmiles(mol, doRandom=True))
        return list(variants)